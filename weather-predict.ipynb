{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Weather: Temperature Forecast\n",
    "\n",
    "With this Jupyter notebook you'll walk through the necessary steps to create your first Azure ML pipeline to preprocess data, train a ML model, and register it. Additionally, you'll deploy this model to the cloud to obtain a REST endpoint for predictions.\n",
    "\n",
    "![image info](./images/tutorial-outline.png)\n",
    "\n",
    "Our dataset of choice is the freely available daily weather data from DWD. A description of the data itself is available [here](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/kl/historical/DESCRIPTION_obsgermany_climate_daily_kl_historical_en.pdf) (English), or alternatively [here](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/kl/historical/BESCHREIBUNG_obsgermany_climate_daily_kl_historical_de.pdf) in German.\n",
    "\n",
    "**Our objective is to predict the average air temperature for the next day based on historical data.** For this we will build a type of recurrent neural network called Long-Short Term Memory (LSTM) using TensorFlow.\n",
    "\n",
    "Note that some datasets are already available in our Azure Machine Learning Workspace. Just take a look which data is available and use the one that suits you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup\n",
    "\n",
    "Fill in or modify these variables according to your needs. \n",
    "\n",
    "In the case of datasets, refer to the Azure ML workspace and see which datasets prefixed with `weather` are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309167627
    }
   },
   "outputs": [],
   "source": [
    "initials = \"\"  # TODO\n",
    "cluster_name = \"\"  # TODO\n",
    "\n",
    "data_name = \"weather-nurnberg\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to an Azure ML Workspace\n",
    "\n",
    "Recall that a Azure ML Workspace manages every resource and asset relatd to Machine Learning such as datasets, models, experiment with their runs, and pipelines with their runs.\n",
    "\n",
    "![image info](./images/azure-machine-learning-taxonomy.png)\n",
    "\n",
    "Connection to a Azure ML (AML) workspace can be accomplished in one of two ways: \n",
    "\n",
    "1. Either from a configuration file, which is downloadable from the Web-UI of the AML workspace itself: \n",
    "   ``` python\n",
    "   ws = Workspace.from_config()\n",
    "   ```\n",
    "2. Connect to workspace by specifying the appropriate parameters:\n",
    "   ``` python\n",
    "   ws = Workspace.get(\n",
    "      name='aml-workspace',\n",
    "      subscription_id='1234567-abcde-890-fgh...',\n",
    "      resource_group='aml-resources'\n",
    "   )\n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309168797
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# connect to workspace from configuration file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "print(\n",
    "    \"Workspace name: \" + ws.name,\n",
    "    \"Azure region: \" + ws.location,\n",
    "    \"Subscription id: \" + ws.subscription_id,\n",
    "    \"Resource group: \" + ws.resource_group,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "\n",
    "According to Merriam-Webster, an experiment is defined as \"an operation or procedure carried out under controlled conditions in order to discover an unknown effect or law, to test or establish a hypothesis, or to illustrate a known law\". With Azure Machine Learning you can manage experiments and different experiment *runs* in an organized manner. Thus, for our weather prediction project, we as well create a dedicated experiment as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309169561
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=\"ex-weather-predict-\" + initials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Use a Compute Cluster\n",
    "\n",
    "Our training pipeline will eventually run somewhere. Two options are available: On your local device, or on a specified compute cluster. In our case today we use a compute cluster. In the following Python cell we first try to get an existing cluster with a specified name. If it is not available yet, we simply create it. In any case, we will wait until the minimum nodes are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309169907
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Check if the compute target exists\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print(\"Found existing cluster.\")\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_DS11_V2\",\n",
    "        min_nodes=0,  # Default value is 0. Anyways, defining zero compute nodes keeps cost at a minimum.\n",
    "        max_nodes=2,\n",
    "    )\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Python Environment \n",
    "\n",
    "Additionally, we need to specify a Python environment. In our case, we will create a new one that satisfies our needs. That is: scikit-learn, pandas, numpy, joblib, and tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309170716
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "env_name = \"weather-predict-\" + initials\n",
    "\n",
    "environment = Environment(env_name)\n",
    "environment.python.user_managed_dependencies = False  # Let Azure ML manage dependencies\n",
    "\n",
    "# Create a set of package dependencies\n",
    "python_packages = CondaDependencies.create(\n",
    "    python_version=\"3.8\",\n",
    "    conda_packages=[\"scikit-learn\", \"pandas\", \"numpy\", \"joblib\", \"tensorflow\"],\n",
    "    pip_packages=[\"azureml-sdk\", \"azureml-defaults\"],\n",
    ")\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "environment.python.conda_dependencies = python_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "environment.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, env_name)\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "# RunConfiguration encapsulates necessary information for submitting training runs\n",
    "# to different compute targets.\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above.\n",
    "pipeline_run_config.target = cluster\n",
    "\n",
    "# Run within a docker container\n",
    "pipeline_run_config.docker = DockerConfiguration(use_docker=True)\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print(\"Run configuration created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also retrieve all existing environments, i.e. all environments created and provided by Azure as well as custom ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309171248
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "environments = Environment.list(workspace=ws)\n",
    "for name in environments:\n",
    "    print(\"Name:\", name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Pipeline\n",
    "\n",
    "Now we'll get to the meat: Creating a training pipeline consisting in the following steps:\n",
    "1. **Preprocess Data**: This step will obtain a dataset name, retrieves the corresponding registered dataset, performs data cleaning, and normalization of input features. It then stores this preprocessed data and normalization information (transformer values) to Azure Storage. This normalization information is then published as a \"dataset\" because we will need it later in a scoring script. A script that receives user data, performs the same data preprocessing and feature normalization in order to retrieve predictions.\n",
    "2. **Train Model**: This step trains a model based on the preprocessed data from the previous step. Additionally, we have several (user) arguments to change or specify the neural networks architecture or even select the type of layer. Currently, only Long-Short Term Memory (LSTM) is implemented. However, you may as well implement other types of network layers as you wish. For instance you could experiment with Gated Recurrent Units (GRU), or simple Recurrent Neural Network (RNN) layers. Whatever the (hyper-)parameters, this step will save any trained model to Azure Storage.\n",
    "3. **Register Model**: This step picks up the previously persistet neural network model and registers it to Azure Machine Learning Workspace. After this step this model can be deployed.\n",
    "\n",
    "For an introduction to LSTMs refer to this [blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.core import Dataset\n",
    "\n",
    "import os\n",
    "\n",
    "# To move data between pipeline steps, we first need to define data \"sinks\".\n",
    "# This can be done with PipelineData or OutputFileDatasetConfig. We'll do\n",
    "# both to demonstrate the difference between these two:\n",
    "\n",
    "# Define a place where our preprocessed data will temporarily live\n",
    "prepped_data = OutputFileDatasetConfig(\"prepped_\" + initials)\n",
    "\n",
    "# Get the default datastore\n",
    "data_store = ws.get_default_datastore()\n",
    "# Define a place where the transformer lives. We can also specify a exact destination with a string template:\n",
    "transformer_data = OutputFileDatasetConfig(\n",
    "    \"transformer_\" + initials, destination=(data_store, \"transformerout/{run-id}\")\n",
    ")\n",
    "\n",
    "# Registers min-max scaling values of column transformer as a new dataset after a specific pipeline has run successfully\n",
    "# (we associate this data sink later).\n",
    "# In case where such a dataset already exits, a new version is created. This will be helpful in our scoring script.\n",
    "transformer_data_name = f\"{data_name}-transformer-{initials}\"\n",
    "output_data_dataset = transformer_data.as_upload(overwrite=True).register_on_complete(\n",
    "    name=transformer_data_name,\n",
    "    description=\"Column transformer values for min-max scaling of features\",\n",
    ")\n",
    "print(\n",
    "    f\"Min-max scaling values will be registered as a dataset under the name of: {transformer_data_name}\"\n",
    ")\n",
    "\n",
    "# Create a place where our trained model will be stored\n",
    "model_folder = PipelineData(\"model_folder_\" + initials, datastore=data_store)\n",
    "\n",
    "# Our model needs a name\n",
    "model_name = f\"{data_name}-model-{initials}\"\n",
    "\n",
    "# Our python scripts live somewhere. See the directory for detailed information.\n",
    "src_dir = \"src\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309520246
    }
   },
   "outputs": [],
   "source": [
    "# Step to run a Python script\n",
    "preprocess = PythonScriptStep(\n",
    "    name=\"Prepare Data\",\n",
    "    source_directory=src_dir,\n",
    "    script_name=\"preprocess/main.py\",\n",
    "    compute_target=cluster,\n",
    "    # Script arguments include PipelineData\n",
    "    arguments=[\n",
    "        \"--dataset_name\",\n",
    "        data_name,\n",
    "        \"--output_folder\",\n",
    "        prepped_data,  # here we have the data sink for our preprocessed data\n",
    "        \"--transformer_folder\",\n",
    "        output_data_dataset,  # here we have the location for our transformer\n",
    "        # you can also play with splitting ratios. Take a look at the script how the arguments are called\n",
    "    ],\n",
    "    runconfig=pipeline_run_config,  # associate the pipeline configuration we previously defined\n",
    "    allow_reuse=True,  # Very useful. When input parameters did not change, this step will not be rebuild. Saves time - and money\n",
    ")\n",
    "print(\"Successfully created data preparation step.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the training parameters. Specifically, set the following parameters:\n",
    "- `sequence_length`\n",
    "- `batch_size`\n",
    "- `epochs`\n",
    "- `patience`\n",
    "- `recurrent_units`: \n",
    "- `recurrent_model_type`: Implement GRU and/or RNN.\n",
    "\n",
    "Keep the following in mind regarding sequence length: Data is prepared for the network such that it has the following shape: `(batch_size, sequence_length, features)`. Our target will be the next day's average air temperature. Following image illustrates one data sequence with sequence of 5 and a number of features of 3. With a batch size of 8, we will feed eight such windows with the corresponding sequence length to the model for training.\n",
    "\n",
    "![image info](./images/data-reshaping.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used as input arguments to the training script.\n",
    "# Play with sequence length.\n",
    "sequence_length = None  # TODO\n",
    "batch_size = None  # TODO play with batch size\n",
    "epochs = None  # TODO play with number of epochs\n",
    "\n",
    "# play with early stopping. This will stop if now change in val loss is registered for a specified number of epochs\n",
    "patience = None  # TODO\n",
    "\n",
    "# play with number of recurrent units. Keep in mind that it is generally good to have lesser units than input sequence length\n",
    "recurrent_units = None  # TODO\n",
    "\n",
    "# go ahead and implement other layers\n",
    "recurrent_model_type = \"LSTM\"  # TODO\n",
    "\n",
    "# play with learning rate. In the case for Adam or Nadam, a learning rate of 0.001 is a good start\n",
    "learning_rate = 0.001\n",
    "\n",
    "# care to implement and use a different optimizer?\n",
    "optimizer = \"nadam\"\n",
    "\n",
    "\n",
    "train = PythonScriptStep(\n",
    "    name=\"Train Model\",\n",
    "    source_directory=src_dir,\n",
    "    script_name=\"train/main.py\",\n",
    "    compute_target=cluster,\n",
    "    # Pass as script argument\n",
    "    arguments=[\n",
    "        \"--input_folder\",\n",
    "        prepped_data.as_input(),  # here we specify out preprocessind folder as input so that our script can read data from it\n",
    "        \"--output_folder\",\n",
    "        model_folder,  # here we have the PipelineData where our model will be stored\n",
    "        \"--model_name\",\n",
    "        model_name,\n",
    "        \"--data_name\",\n",
    "        data_name,\n",
    "        \"--sequence_length\",\n",
    "        sequence_length,\n",
    "        \"--learning_rate\",\n",
    "        learning_rate,\n",
    "        \"--batch_size\",\n",
    "        batch_size,\n",
    "        \"--epochs\",\n",
    "        epochs,\n",
    "        \"--recurrent_model_type\",\n",
    "        recurrent_model_type,\n",
    "        \"--recurrent_units\",\n",
    "        recurrent_units,\n",
    "        \"--optimizer_name\",\n",
    "        optimizer,\n",
    "        \"--early_stopping_patience\",\n",
    "        patience,\n",
    "    ],\n",
    "    outputs=[\n",
    "        model_folder\n",
    "    ],  # Note that any PipelineData additionally need to be specified as output, and as input if it is used as an input\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=True,\n",
    ")\n",
    "print(\"Successfully created model training step.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register = PythonScriptStep(\n",
    "    name=\"Register Model\",\n",
    "    source_directory=src_dir,\n",
    "    script_name=\"register/main.py\",\n",
    "    arguments=[\n",
    "        \"--input_folder\",\n",
    "        model_folder,  # specify our model folder to read from\n",
    "        \"--model_name\",\n",
    "        model_name,  # our saved model will have a specific name\n",
    "        \"--register_model_name\",\n",
    "        model_name,  # we can also specify a different name to register it to Azure\n",
    "    ],\n",
    "    inputs=[\n",
    "        model_folder\n",
    "    ],  # here our PipelineData is used as an input, thus we also need to specify it as an input. Quite cumbersome, isn't it?\n",
    "    compute_target=cluster,\n",
    "    runconfig=pipeline_run_config,\n",
    "    allow_reuse=False,\n",
    ")\n",
    "print(\"Successfully created model registration step.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying each step, we can build our Azure ML pipeline and submit it, i. e. execute those specified steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638309803092
    }
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Construct the pipeline\n",
    "train_pipeline = Pipeline(workspace=ws, steps=[preprocess, train, register])\n",
    "\n",
    "# run the pipeline\n",
    "run = experiment.submit(train_pipeline)\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Run Metrics\n",
    "\n",
    "We can take a look at metrics like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310127602
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "for step_run in run.get_children():\n",
    "    print(\"{}: {}\".format(step_run.name, step_run.get_metrics()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Let's plot the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310127978
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    logged_metrics = [\n",
    "        metric for metric in history.keys() if not metric.startswith(\"val\")\n",
    "    ]\n",
    "\n",
    "    for logged_metric in logged_metrics:\n",
    "        plt.plot(history[logged_metric])\n",
    "        plt.plot(history[\"val_\" + logged_metric])\n",
    "        plt.title(f\"Learning curve for: {logged_metric.upper()}\")\n",
    "        plt.ylabel(logged_metric)\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310136539
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "for step_run in run.get_children():\n",
    "    if step_run.name == \"Train Model\":\n",
    "        plot_history(step_run.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can view them in Azure Machine Learning workspace under your experiment or specific run. See where you can find your metrics in Azure Machine Lerning Workspace browser. You can also add new plots to your experiment page like in the following screenshot:\n",
    "\n",
    "![image info](./images/experiment-metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all  Registerd Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310145931
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, \"version:\", model.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "We successfully created a training pipeline, run this pipeline and produced a model. Now we want to deploy it. Before we deploy it to an Azure Container Instance (ACI) we will deploy it locally. This is good practice as we can debug more easily. Let's see what we need for deployment:\n",
    "1. Python Environment.\n",
    "2. In our case we need to download the transformer dataset so that we can scale our features accordingly.\n",
    "3. Inference configuration that points to our scoring script.\n",
    "4. Deployment configuration. For local deployment this will be a local web service, for cloud deployment to an ACI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define or Reuse an Inference Environment\n",
    "\n",
    "A deployment configuration needs a python envronment. We try to reuse our previously created environment, but we can also specify a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310148694
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    registered_env = Environment.get(workspace=ws, name=env_name)\n",
    "except:\n",
    "    print(\"Environment not found, will create it.\")\n",
    "\n",
    "    inference_environment = Environment(env_name)\n",
    "    inference_environment.python.user_managed_dependencies = (\n",
    "        False  # Let Azure ML manage dependencies\n",
    "    )\n",
    "\n",
    "    # Create a set of package dependencies\n",
    "    python_packages = CondaDependencies.create(\n",
    "        python_version=\"3.8\",\n",
    "        conda_packages=[\"scikit-learn\", \"pandas\", \"numpy\", \"joblib\", \"tensorflow\"],\n",
    "        pip_packages=[\"azureml-sdk\", \"azureml-defaults\"],\n",
    "    )\n",
    "\n",
    "    # Add the dependencies to the environment\n",
    "    environment.python.conda_dependencies = python_packages\n",
    "\n",
    "    # Register the environment (just in case you want to use it again)\n",
    "    environment.register(workspace=ws)\n",
    "    registered_env = Environment.get(ws, env_name)\n",
    "else:\n",
    "    print(f'Using existing environment named \"{env_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Column Transformer from Datastore\n",
    "\n",
    "In our preprocessing step we not only cleaned the data, but also scaled the features. We stored these normalization information and now we need to download them to be accessible for our scoring script.\n",
    "\n",
    "**TODO: Please specify the same sequence length in the scoring script as defined above for model training. (see `src/score/main.py`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310152633
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name=transformer_data_name)\n",
    "dataset.download(target_path=os.path.join(src_dir, \"score\"), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering why we do not need to download the model itself. We will get the model information later. But, we only need the reference and not download it. This is because Azure already mounts the model into our docker container for us. Why downloading then the transformer information? We cannot access our Azure Machine Learning Workspace from within our scoring script. Well, we could, but we then would need to place our credentials into our docker container. This is not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model to Local  Webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Inference Configuration\n",
    "\n",
    "Like our pipeline steps holds information to our scripts, an inference configuration does the same. It points to the right python environment, source directory that is then mounted into the docker container and specifies an entry step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310153901
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "src_dir = \"src\"\n",
    "\n",
    "dummy_inference_config = InferenceConfig(\n",
    "    environment=registered_env,  # we will reuse our training environment\n",
    "    source_directory=src_dir,\n",
    "    entry_script=\"score/main.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Deployment Configuration\n",
    "\n",
    "We first deploy locally. Therefore, we specify a `LocalWebservice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310155667
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "local_deployment_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Your Model\n",
    "\n",
    "Previously, in the registration step, we published our trained model such that Azure Machine Learninig knows about it and we can reuse it. Note that every model is associated with its own version number. This provides the ability to specify a model by its name, i. e. pin a model used for deployment to a predefined version. Here we simply use the lates version by not specifying a version number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310157322
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model(ws, model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Model to Local Webservice\n",
    "\n",
    "At last, we can deploy locally. Simply hit `Model.deploy` and specify every other element we created (inference configuration, deployment configuration, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310185838
    }
   },
   "outputs": [],
   "source": [
    "service_name = \"weather-predict-service-\" + initials\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=service_name,\n",
    "    models=[model],\n",
    "    inference_config=dummy_inference_config,\n",
    "    deployment_config=local_deployment_config,\n",
    "    overwrite=True,  # Overwrite if there is already a local webservice with the same port running\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case where you already deployed your model but did run into problems, you can reload your fixed service with the following code. No need to re-deploy again, simply reload your webservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638307669046
    }
   },
   "outputs": [],
   "source": [
    "service.reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Your Dataset For Prediction\n",
    "\n",
    "Before calling the webservice, we need data. Thus, we get the same dataset but specify different samples. In our case here we use the last 60 days for which we want a prediction. (Keep in mind that we get fewer predictions depending on your sequence length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310186607
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, name=\"weather-nurnberg\")\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "# take last 60 days\n",
    "to_predict = df.iloc[-180:, :]\n",
    "to_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Into Your Local Webserivce\n",
    "\n",
    "Now we can actually call the REST-service that has been provided for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310187550
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"http://localhost:6789\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = json.dumps({\"data\": to_predict.to_dict(\"records\")})\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was your call successful? Let's check the logs with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638307577421
    }
   },
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to Azure Container Instance\n",
    "\n",
    "After successful local deployment and testing we can deploy our service to the cloud. For this we need the same steps as with local deployment except for the `LocalWebservice`, which we will change to `AciWebservice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310465074
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "\n",
    "crml_env = Environment.get(workspace=ws, name=env_name)\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=crml_env,\n",
    "    source_directory=src_dir,\n",
    "    entry_script=\"score/main.py\",\n",
    ")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=0.5,  # Small amount of GPU is sufficient for our needs here\n",
    "    memory_gb=1,  # Same goes for RAM. Our model and data (typically) are not large\n",
    "    auth_enabled=True,  # Specify authentication with True\n",
    ")\n",
    "\n",
    "cloud_service = Model.deploy(\n",
    "    ws,\n",
    "    service_name,\n",
    "    [model],\n",
    "    inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "cloud_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310770940
    }
   },
   "outputs": [],
   "source": [
    "print(cloud_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Into Your Remote Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310776900
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from azureml.core import Webservice\n",
    "\n",
    "deployed_cloud_service = Webservice(workspace=ws, name=service_name)\n",
    "scoring_uri = deployed_cloud_service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "key, _ = deployed_cloud_service.get_keys()\n",
    "\n",
    "# Set the appropriate headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "\n",
    "data = json.dumps({\"data\": to_predict.to_dict(\"records\")})\n",
    "response = requests.post(scoring_uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310779737
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = pd.DataFrame.from_records(response.json()[\"result\"])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Your Prediction Any Good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot True vs. Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310783029
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.tsa.api as smt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310784700
    }
   },
   "outputs": [],
   "source": [
    "def plot_prediction(true, predicted, label_true=\"true\", label_predicted=\"predicted\"):\n",
    "    # x = list(range(len(predicted)))\n",
    "    x = true.index\n",
    "    plt.plot(x, true, label=label_true)\n",
    "    plt.plot(x, predicted, label=label_predicted)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310785639
    }
   },
   "outputs": [],
   "source": [
    "plot_prediction(to_predict.iloc[sequence_length:-1, -1], predictions.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310793066
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(\n",
    "    to_predict.iloc[sequence_length:-1, -1], predictions.iloc[:, -1], squared=True\n",
    ")\n",
    "mse = mean_squared_error(\n",
    "    to_predict.iloc[sequence_length:-1, -1], predictions.iloc[:, -1], squared=False\n",
    ")\n",
    "\n",
    "print(f\"RMSE: {rmse}\\nMSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis\n",
    "\n",
    "According to statistician and researcher [Rob J. Hyndman](https://otexts.com/fpp3/diagnostics.html), good predictions have the following properties when taking a closer look at its residuals, i. e. errors (true minus predicted values):\n",
    "1. Residuals are uncorrelated. Correlation means that there is still unused information. Using these information generally result in a better model.\n",
    "2. Residuals have zero mean. Residuals with no zero mean indicate bias in the model.\n",
    "\n",
    "Additionally, the following properties can be helpful as well although they are not necessary:\n",
    "1. Residuals have constant variance (\"homoscedasticity\").\n",
    "2. Residuals are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310808274
    }
   },
   "outputs": [],
   "source": [
    "def residual_analysis(y, lags=None, figsize=(10, 8)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n",
    "    acf_ax = plt.subplot2grid(layout, (1, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    sns.lineplot(x=list(range(len(y))), y=y, ax=ts_ax)\n",
    "\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    sns.distplot(y, ax=hist_ax)\n",
    "    acf_ax.set_xlim(1.5)\n",
    "    # acf_ax.set_ylim(-0.1, 0.2)\n",
    "    fig.suptitle(f\"Residual Analysis, Residual mean: {np.mean(y):.4f}\")\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1638310811037
    }
   },
   "outputs": [],
   "source": [
    "true = to_predict.iloc[sequence_length:-1, -1].to_numpy()\n",
    "pred = predictions.iloc[:, -1].to_numpy()\n",
    "residuals = true - pred\n",
    "residuals.shape\n",
    "residual_analysis(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "\n",
    "- Manually delete not needed experiment runs or the whole experiment itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete deployed webservice\n",
    "deployed_cloud_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps?\n",
    "Our pipeline-code so far seems production ready, we specified all the needed steps and even deployed to an ACI. But are we really ready to deploy to production and go home?\n",
    "\n",
    "Here are a few things to consider:\n",
    "- Pipeline creation and submission was orchestrated from within this very Jupyter Notebook. This may not be good for an automated deployment.\n",
    "- What if data changed? As of now, we would need to manually register this new data to our Azure Machine Learning Workspace and execute this Jupyter Notebook.\n",
    "- Of course we could publish our Azure ML pipeline, but this only gives us a REST endpoint to trigger the execution of data preprocessing, model training, and model registration. \n",
    "- We may not want every pipeline excution to register a new model if the new model performs poorly compared to the already registered/deployed model. Thus, we may want an evaluation step that decides that for us.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
